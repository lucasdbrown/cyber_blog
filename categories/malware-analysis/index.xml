<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Malware Analysis on Lucas Brown — Cybersecurity Blog</title><link>https://lucasdbrown.github.io/cyber_blog/categories/malware-analysis/</link><description>Recent content in Malware Analysis on Lucas Brown — Cybersecurity Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>© 2025 Lucas Brown</copyright><lastBuildDate>Fri, 26 Sep 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://lucasdbrown.github.io/cyber_blog/categories/malware-analysis/index.xml" rel="self" type="application/rss+xml"/><item><title>From Prompts to Payloads: Inside MalTerminal and the Rise of AI-Enabled Malware</title><link>https://lucasdbrown.github.io/cyber_blog/posts/malterminal/</link><pubDate>Fri, 26 Sep 2025 00:00:00 +0000</pubDate><guid>https://lucasdbrown.github.io/cyber_blog/posts/malterminal/</guid><description>&lt;h2 class="relative group"&gt;Discovery of MalTerminal
&lt;div id="discovery-of-malterminal" class="anchor"&gt;&lt;/div&gt;
&lt;span
class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100 select-none"&gt;
&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700 !no-underline" href="#discovery-of-malterminal" aria-label="Anchor"&gt;#&lt;/a&gt;
&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;SentinelOne’s research team discovered a new malware, which they call MalTerminal, and claim it is one of the earliest examples of malware with LLM capabilities embedded into it. MalTerminal malware samples were found to contain an OpenAI 2023 API endpoint that was deprecated, hinting that it was one of the earliest malware samples to utilize LLMs. MalTerminal is a program (Python scripts compiled as a Windows executable) that doesn’t carry its malicious logic inside the file. Instead, it asks an LLM (GPT-4) to write the malicious code when it runs. When you run it, the operator picks what they want, either to make ransomware or a reverse shell. That instruction becomes the prompt the malware sends to GPT-4 via an API call. The LLM then generates code tailored to that request. The malware contains hardcoded API keys and carefully crafted prompts (these are embedded in the scripts/binary). SentinelOne found these keys/prompts while hunting binaries.&lt;/p&gt;</description></item></channel></rss>